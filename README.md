# VeloNorth - Sales Analytics & BI Pipeline

This repository contains the end-to-end solution for the **"Bikes Sales BI & Data Modelling Challenge"**.  
The project features a robust, automated data pipeline built with Python and a final interactive analytics dashboard developed with **Streamlit**.

---

## ğŸš€ Project Overview
The primary goal of this project is to transform a raw dataset of nine CSV files into a clean, robust analytical data model and use it to deliver **key business insights**.  

The solution follows professional **software engineering** and **data engineering** best practices, including modular code, configuration management, and automated data processing.

### Key Features
- **Automated Data Pipeline**: Multi-stage pipeline (Ingestion, Validation, Transformation, Modelling) that processes raw data into an analysis-ready format.  
- **Robust Data Modelling**: Implements a **Star Schema** with a central fact table and multiple dimension tables, optimized for BI reporting.  
- **Comprehensive Data Quality Checks**: Automatically handles common data quality issues like duplicate keys, inconsistent values, and schema mismatches.  
- **Interactive Analytics Dashboard**: Built with **Streamlit**, offering dynamic filtering, currency conversion, and answers to key business questions.  
- **Professional Documentation**: Includes detailed reports on data quality, model schema, and business insights.  

---

## ğŸ› ï¸ Tech Stack
- **Language**: Python 3.9+  
- **Data Processing**: pandas  
- **Dashboard**: Streamlit 
- **Prototyping**: Power BI  
- **Core Libraries**: python-box, ensure, nbformat, requests, zipfile

---

## ğŸ“‚ Project Structure
The project follows a **modular and scalable structure** to separate concerns:

```
â”œâ”€â”€ data/              # Stores data assets (raw, processed, presentation)
â”œâ”€â”€ docs/              # Documentation (Data Quality, Model Schema, etc.)
â”œâ”€â”€ notebooks/         # Jupyter notebooks for exploratory data analysis (EDA)
â”œâ”€â”€ src/               # Main source code for the application
â”‚   â”œâ”€â”€ components/    # Components for each pipeline stage
â”‚   â”œâ”€â”€ config/        # Configuration management
â”‚   â”œâ”€â”€ entity/        # Configuration data structures
â”‚   â”œâ”€â”€ pipeline/      # Orchestration scripts
â”‚   â”œâ”€â”€ logger_config/ # Custom logging configuration
â”‚   â””â”€â”€ utils.py       # Utility functions
â”œâ”€â”€ app.py             # Streamlit dashboard entry point
â”œâ”€â”€ main.py            # Runs the entire data pipeline
â”œâ”€â”€ config.yaml        # Main configuration file
â”œâ”€â”€ schema.yaml        # Data schema definitions
â”œâ”€â”€ setup.py           # Makes the project installable as a package
â””â”€â”€ requirements.txt   # Python dependencies
```

---

## âš™ï¸ Setup and Installation

### 1. Clone the Repository
```bash
git clone https://github.com/ArthurMaciell/VeloAnalytics.git
cd VeloAnalytics
```

### 2. Create and Activate a Virtual Environment
```bash
# Create the environment
python -m venv .venv

# Activate the environment
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install the Project as a Local Package
This makes the custom modules importable:
```bash
pip install -e .
```

---

## â–¶ï¸ How to Run

### 1. Run the Data Pipeline
Processes raw CSVs into the final analytical model:
```bash
python main.py
```
This executes **Ingestion â†’ Validation â†’ Transformation â†’ Modelling** and outputs the final data to `data/03_presentation/`.

### 2. Launch the Interactive Dashboard
```bash
streamlit run src/app.py
```
Opens the **Streamlit dashboard** in your default web browser.

---

## ğŸ“š Project Documentation
This repository includes detailed documentation covering the key aspects of the challenge:

- **Data Quality Assessment Report** â†’ Issues identified & automated fixes.  
- **Analytical Data Model Schema** â†’ Star Schema sketch with keys & relationships.  
- **Business Metrics Definitions** â†’ Logic for KPIs (Revenue, AOV, Conversion, etc.).  
- **Model Enrichment Proposals** â†’ External data integration & predictive forecasting.  
- **Business Insights & Assumptions** â†’ Key insights delivered by the dashboard.  

---
